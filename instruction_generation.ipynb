{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from retry import retry\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "system_message = (\n",
    "        \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "        \"You will be given a medical image and one or multiple bounding box coordinates, \"\n",
    "        \"These coordinates are in the form of bounding boxes, represented as (x1, y1, x2, y2) with floating numbers ranging from 0 to 1, \"\n",
    "        \"as they are the coordinates of upper left corner and lower right corner of the bounding box, normalized by the size of original image.\\n\"\n",
    "        \"To accomplish this, you will use a detection model named grounding dino that can detect organ or any disease region in a medical image.\\n\"\n",
    "        \"You will first question yourself from a THIRD perspective as a USER about what do you need to do to address this task.\\n\"\n",
    "        \"And for this questioning, write an answer that you think would be appropriate. Your response's format should be:\\n\"\n",
    "        \"'Question: your question from a third perspective and the question should not contain things like 'using the provided coordinates' because the detection process will only condition on prompts \\nAnswer: <thoughts> your thoughts about the question and the answer, and your intended approach including the tool you choose \\n\"\n",
    "        \"<actions> [{'tool name': API name, 'tool params': some parameters}]\\n <values> the final results'. \\n\"\n",
    "        \"When questioning, you should mimic the user be questioning you how to achieve the goal.\\n\"\n",
    "        \"The API name in this case should be \\\"grounding dino\\\" or None. And you need to explicitly include the brackets like <actions> and strictly follow the template format.\\n\"\n",
    "        \"You will use these bounding boxes to tell the user the result of your detection.\\n\"\n",
    "        \"Ask diverse questions and give corresponding answers. Only include questions that have definite answers. Do not ask any questions that cannot be answered confidently.\\n\"\n",
    "        \"Feel free to have more variance in expression when asking the question, elaborating your thoughts, and stating the values, so long as they make sense and meet the previous requirements.\"\n",
    "    )\n",
    "\n",
    "user_message_1_list = {\n",
    "    \"abdomen\":(\n",
    "    \"An abdominal 2D CT scan showing the kidney and liver.\\n\\n\"\n",
    "    \"kidney: [0.25, 0.55, 0.41, 0.68],\\n\"\n",
    "    \"kidney: [0.58, 0.54, 0.77, 0.68],\\n\"\n",
    "    \"liver: [0.48, 0.25, 0.55, 0.29]\\n\"\n",
    "    ),\n",
    "    \"lung\":\"a 2D x-ray chest scan showing lungs\\nlung: [0.1, 0.05, 0.47, 0.78]\\nlung: [0.55, 0.05, 0.87, 0.8]\\n\",\n",
    "    \"tumor\":\"an mri brain image with tumor\\ntumor: [0.35, 0.35, 0.52, 0.61]\\n\",\n",
    "    \"disease\": \"a 2D x-ray chest scan showing disease\\ncardiomegaly: [0.39, 0.46, 0.79, 0.6]\\n\"\n",
    "}\n",
    "user_message_2 = (\n",
    "        \"An abdominal 2D CT scan showing spleen, kidney, stomach and liver.\\n\\n\"\n",
    "        \"spleen: [0.61, 0.3, 0.74, 0.5]\\n\" \n",
    "        \"kidney: [0.27, 0.54, 0.36, 0.63]\\n\" \n",
    "        \"stomach: [0.42, 0.33, 0.62, 0.46]\\n\"\n",
    ")\n",
    "user_message_3 = (\n",
    "        \"A histology image containing many cells\\n\\n\" \n",
    "        \"cells:[0.56,0.57,0.75,0.78],[0.48,0.33,0.64,0.58],[0.32,0.0,0.45,0.12],[0.85,0.61,0.98,0.81],[0.31,0.31,0.49,0.53],[0.63,0.33,0.79,0.57],[0.3,0.11,0.41,0.26],[0.42,0.86,0.52,1.0],[0.0,0.19,0.06,0.39],[0.76,0.93,0.84,1.0],[0.85,0.38,0.94,0.5],[-0.0,0.0,0.05,0.1]\"\n",
    "    )\n",
    "\n",
    "assist_abdomen_qlist = [\n",
    "    \"Can you locate the kidney and liver in this image and and segment them?\",\n",
    "    \"Could you identify the positions of the kidney and liver and segment them in this image?\",\n",
    "    \"Could you show where the kidney and liver are located in this image and segment them?\",\n",
    "    \"Can you highlight the kidney and liver in this image and segment them?\",\n",
    "    \"Identify the kidney and segment the liver in this image\",\n",
    "    \"Detect the kidney and segment the liver in this image\"\n",
    "]\n",
    "\n",
    "assist_tumor_qlist = [\n",
    "    \"Can you locate the tumor in this brain image and and segment it?\",\n",
    "    \"Could you identify the position of brain tumor and segment it in this image?\",\n",
    "    \"Could you show where the tumor is located and segment it in this image?\",\n",
    "    \"Can you highlight the brain tumor and segment it in this image?\",\n",
    "    \"Identify the tumor and segment it in this brain image\"\n",
    "]\n",
    "\n",
    "assist_disease_qlist = [\n",
    "    \"Can you locate the region of cardiomegaly in this image and confirm its presence?\",\n",
    "    \"Could you identify the position of cardiomegaly in this chest image?\",\n",
    "    \"Could you show where the cardiomegaly is located in this image?\",\n",
    "    \"Can you highlight the cardiomegaly region in this image?\",\n",
    "    \"Can you identify cardiomegaly in this xray image?\"\n",
    "]\n",
    "\n",
    "assist_lung_qlist = [\n",
    "    \"Can you locate and segment the lungs in this chest image?\",\n",
    "    \"Could you identify the position of lungs and segment them in this xray image?\",\n",
    "    \"Could you show where the lungs are located in this image and do a segmenattion?\",\n",
    "    \"Can you highlight the lungs in this image and segment them?\",\n",
    "    \"Can you identify the lungs in this xray image and segment them?\"\n",
    "]\n",
    "\n",
    "assist_2_qlist = [\n",
    "    \"Can you identify the spleen, kidney, stomach and liver and segment them in this abdominal 2D CT scan image?\",\n",
    "    \"Is it possible to distinguish the spleen, kidney, stomach, and liver in this abdominal 2D CT scan and segment all of them?\",\n",
    "    \"Could you point out the spleen, kidney, stomach, and liver in this 2D CT scan of the abdomen and do a segmentation?\",\n",
    "    \"Identify the spleen, kidney, stomach and liver and segment them in this abdominal 2D CT scan image\"\n",
    "]\n",
    "\n",
    "assist_3_qlist = [\n",
    "    \"Can you detect the cells in this histology image, give me the total numbers and segment them? \",\n",
    "    \"Could you detect, count and segment all the cells present in this histology image?\",\n",
    "    \"Is it feasible to enumerate the cells visible and segment them in this histology image?\",\n",
    "    \"Can this histology image be processed to reveal the total number of cells and segment them?\",\n",
    "    \"Could you examine this histology image, provide a count of the cells and segment them?\",\n",
    "]\n",
    "\n",
    "assistant_message_1_templates = {\n",
    "    'abdomen': (\n",
    "        \"Question:\\n\\n\"\n",
    "        \"<q>\\n\\n\"\n",
    "        \"Answer:\\n\\n\"\n",
    "        \"<thoughts> It would be beneficial to utilize a detection model to identify the organ, kidney and liver and then use a medical segmentation tool to give a result, which will provide more accurate results.\\n\\n\"\n",
    "        \"<actions> [{'API name': 'grounding dino + MedSAM', 'API params': {'image': '<imagepath>', 'prompts': ['kidney', 'kidney', 'liver']}}]\\n\\n\"\n",
    "        \"<values>\"\n",
    "        \"Based on the bounding box coordinates detected, the image contains two kidneys and liver. Here’s a summary of their positions:\\n\\n\"\n",
    "        \"1. The first kidney is located towards the left of the image, with bounding box coordinates of [  0.25,    0.55,  0.41,    0.68  ], the second kidney is showed on the right of the image, with bounding box coordinates of  [  0.58,    0.54,    0.77,   0.68   ], they are symmetrical along the midline in the image.\\n\\n\"\n",
    "        \"2. The liver is located in the middle upper part of the image with bounding box coordinates [0.48,   0.25,   0.55,   0.29] and is relatively small, indicating that this image is taken at the beginning or end of the liver.\\n\\n\"\n",
    "        \"Based on the output of grounding dino, the segmentation result is showed:\"\n",
    "    ),\n",
    "    'tumor': (\n",
    "        \"Question:\\n\\n\"\n",
    "        \"<q>\\n\\n\"\n",
    "        \"Answer:\\n\\n\"\n",
    "        \"<thoughts> I will use grounding dino to detect the tumor and then use MedSAM to segment it.\\n\\n\"\n",
    "        \"<actions> [{'API name': 'grounding dino + MedSAM', 'API params': {'image': '<imagepath>', 'prompts': ['tumor']}}]\\n\\n\"\n",
    "        \"<values>\"\n",
    "        \"The detected tumor in the MRI brain image is located with bounding box coordinates [0.35, 0.35, 0.52, 0.61]. This indicates that the tumor is situated in the central region of the brain, slightly towards the right and extending downwards. This information is vital for medical evaluation and treatment planning.\\n\"\n",
    "        \"And I have segmented the tumor as below:\"\n",
    "    ),\n",
    "    'disease': (\n",
    "        \"Question:\\n\\n\"\n",
    "        \"<q>\\n\\n\"\n",
    "        \"Answer:\\n\\n\"\n",
    "        \"<thoughts>  Using the grounding dino detection and then MedSAM model will help in identifying and segmenting the presence and region of cardiomegaly in the chest X-ray scan.\\n\\n\"\n",
    "        \"<actions> [{'API name': 'grounding dino + MedSAM', 'API params': {'image': '<imagepath>', 'prompts': ['cardiomegaly']}}]\\n\\n\"\n",
    "        \"<values>\"\n",
    "        \"Based on the grounding dino model output, the presence of cardiomegaly is indicated in the chest X-ray. The region of cardiomegaly is located with bounding box coordinates [0.39, 0.46, 0.79, 0.6]. This suggests an enlargement of the heart, as evidenced by the abnormal size and position within the chest cavity.\\n\\n\"\n",
    "        \"The segmentation result is as below:\"\n",
    "    ),\n",
    "    'lung': (\n",
    "        \"Question:\\n\\n\"\n",
    "        \"<q>\\n\\n\"\n",
    "        \"Answer:\\n\\n\"\n",
    "        \"<thoughts>  Use the grounding dino to ground the lung and then use MedSAM to segment it could help in a more accurate result.\\n\\n\"\n",
    "        \"<actions> [{'API name': 'grounding dino + MedSAM', 'API params': {'image': '<imagepath>', 'prompts': ['lung', 'lung']}}]\\n\\n\"\n",
    "        \"<values>\"\n",
    "        \"Based on the bounding box coordinates detected, the image contains two lungs. Here’s a summary of their positions:\\n\\n1. The first lung is located on the left side of the image, with bounding box coordinates of [0.1, 0.05, 0.47, 0.78].\\n\\n2. The second lung is positioned on the right side of the image, with bounding box coordinates of [0.55, 0.05, 0.87, 0.8].\\n\\nThis identification provides a clear understanding of the lungs' presence and their precise locations in the chest x-ray scan.\\n\\n\"\n",
    "        \"And the segmentation result is as below: which may help you in further medical analysis.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "assistant_message_2_template = (\n",
    "        \"Question:\\n\\n\"\n",
    "        \"<q>\\n\\n\"\n",
    "        \"Answer:\\n\\n\"\n",
    "        \"<thoughts> Employing the grounding dino detection model will precisely identify the spleen, kidney, and liver ,and then I will use the segmentation model to segment the label given the boundingbox. This will help in giving an accurate summary of the organs present in the image.\\n\\n\"\n",
    "        \"<actions> [{'API name': 'grounding dino + MedSAM', 'API params': {'image': '<imagepath>', 'prompts': ['spleen', 'kidney', 'stomach']}}]\\n\\n\"\n",
    "        \"<values> \"\n",
    "        \"Here’s a summary:\\n\\n\"\n",
    "        \"1. The spleen is positioned towards the right middle of the image, with bounding box coordinates of [ 0.61, 0.3, 0.74, 0.5 ].\\n\\n\"\n",
    "        \"2. There is one kidney located towards the left middle of the image with bounding box coordinates [0.27, 0.54, 0.36, 0.63]. This suggests that the subject might have only one kidney or there may be a disparity between the two kidneys.\\n\\n\"\n",
    "        \"3. The stomach is present in the middle part of the image with bounding box coordinates [0.42, 0.33,  0.62, 0.46 ].\\n\\n\"\n",
    "        \"However, there is no liver detected in this image. This identification is based on the provided coordinates and the detection outcome from the grounding dino model, which may help you do more medical analysis.\\n\\n\"\n",
    "        \"Finally, the segmentation result is as below:\"\n",
    ")\n",
    "\n",
    "assistant_message_3_template =(\n",
    "        \"Question:\\n\\n\"\n",
    "        \"<q>\\n\\n\"\n",
    "        \"Answer:\\n\\n\"\n",
    "        \"<thoughts> Employing a detection model and then segmentation model will precisely identify and segment the cell. This will help in giving an accurate result.\\n\\n\"\n",
    "        \"<actions> [{'API name': 'grounding dino + MedSAM', 'API params': {'image': '<imagepath>', 'prompts': ['cell']}}]\\n\\n\"\n",
    "        \"<values>\"\n",
    "        \"According to the output of grounding dino, there are 12 cells in this image.\\n\\n\"\n",
    "        \"I've segment all of them:\"\n",
    ")\n",
    "\n",
    "@retry(exceptions=openai.error.RateLimitError, tries=3, delay=2, backoff=2)\n",
    "def call_gpt4o(system_message, user_message_1, assistant_message_1, user_message_2, assistant_message_2, user_message_3, assistant_message_3, user_message_final, temperature=0.95, max_tokens=2000, top_p=0.95, top_k=None):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message_1},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_message_1},\n",
    "        {\"role\": \"user\", \"content\": user_message_2},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_message_2},\n",
    "        {\"role\": \"user\", \"content\": user_message_3},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_message_3},\n",
    "        {\"role\": \"user\", \"content\": user_message_final}\n",
    "    ]\n",
    "    request_params = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "    }\n",
    "    if top_k is not None:\n",
    "        request_params[\"top_k\"] = top_k\n",
    "    response = openai.ChatCompletion.create(**request_params)\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def process(item, case_counter, Stop_cnt):\n",
    "    \n",
    "    prompts = item['prompt']\n",
    "    phrases = item['phrases']\n",
    "    \n",
    "    if item['boxes']:\n",
    "        if \"Kidney.\" in prompts:\n",
    "            # return None\n",
    "            if case_counter[\"abdomen\"] >= Stop_cnt:\n",
    "                return None\n",
    "            cat = \"abdomen\"\n",
    "            user_message_final = \"a 2D abdominal CT image containing \" + \", \".join(phrases[:-1]) + \" and \" + phrases[-1] + \"\\n\"\n",
    "            for i, phrase in enumerate(phrases):\n",
    "                user_message_final += f\"{phrase}: {item['boxes'][i]}\\n\"\n",
    "            assistant_message_1 = assistant_message_1_templates[\"abdomen\"].replace(\"<q>\", random.choice(assist_abdomen_qlist))\n",
    "            user_message_1 = user_message_1_list[\"abdomen\"]\n",
    "        elif \"lung\" in prompts:\n",
    "            if case_counter[\"lung\"] >= Stop_cnt:\n",
    "                return None\n",
    "            cat = \"lung\"\n",
    "            user_message_final = \"a 2D x-ray chest scan showing lungs\\n\"\n",
    "            for i, phrase in enumerate(phrases):\n",
    "                user_message_final += f\"{phrase}: {item['boxes'][i]}\\n\"\n",
    "            assistant_message_1 = assistant_message_1_templates[\"lung\"].replace(\"<q>\", random.choice(assist_lung_qlist))\n",
    "            user_message_1 = user_message_1_list[\"lung\"]\n",
    "        elif \"cell\" in prompts:\n",
    "            if case_counter[\"cell\"] >= Stop_cnt:\n",
    "                return None\n",
    "            cat = \"cell\"\n",
    "            user_message_final = \"a histology image containing many cells\\n\"\n",
    "            for i, phrase in enumerate(phrases):\n",
    "                user_message_final += f\"{phrase}: {item['boxes'][i]}\\n\"\n",
    "            assistant_message_1 = assistant_message_1_templates[\"abdomen\"].replace(\"<q>\", random.choice(assist_abdomen_qlist))\n",
    "            user_message_1 = user_message_1_list[\"abdomen\"]\n",
    "        elif \"tumor\" in prompts:\n",
    "            # return None\n",
    "            if case_counter[\"tumor\"] >= Stop_cnt:\n",
    "                return None\n",
    "            cat = \"tumor\"\n",
    "            user_message_final = \"an mri brain image with tumor\\n\"\n",
    "            for i, phrase in enumerate(phrases):\n",
    "                user_message_final += f\"{phrase}: {item['boxes'][i]}\\n\"\n",
    "            assistant_message_1 = assistant_message_1_templates[\"tumor\"].replace(\"<q>\", random.choice(assist_tumor_qlist))\n",
    "            user_message_1 = user_message_1_list[\"tumor\"]      \n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        assistant_message_2 = assistant_message_2_template.replace(\"<q>\", random.choice(assist_2_qlist))\n",
    "        assistant_message_3 = assistant_message_3_template.replace(\"<q>\", random.choice(assist_3_qlist))\n",
    "\n",
    "        try:\n",
    "            thinkings = call_gpt4o(system_message, user_message_1, assistant_message_1, user_message_2, assistant_message_2, user_message_3, assistant_message_3, user_message_final)\n",
    "            case_counter[cat] += 1\n",
    "            if sum(case_counter.values())%100 == 0:\n",
    "                print(case_counter)\n",
    "            return {\n",
    "                    \"data\": item[\"image_path\"],\n",
    "                    \"prompt\": item[\"prompt\"],\n",
    "                    \"boxes\": item[\"boxes\"],\n",
    "                    \"logits\": item[\"logits\"],\n",
    "                    \"phrases\": item[\"phrases\"],\n",
    "                    \"category\": item['category'],\n",
    "                    \"user_message\": user_message_final,\n",
    "                    \"response\": thinkings\n",
    "                    }\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def gen_intruct(api_key):\n",
    "    # replact with your api here\n",
    "    openai.api_key = api_key\n",
    "    with open('./dino_final_example.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    results = []\n",
    "    output_json = './dino_instruct_0529_1.json'\n",
    "    if os.path.exists(output_json):\n",
    "        with open(output_json, 'r') as file:\n",
    "            results = json.load(file)\n",
    "\n",
    "    # start_index = len(results)\n",
    "    # data_to_process = data[start_index:]\n",
    "    data_to_process, already = [], []\n",
    "    case_counter = {\"abdomen\": 0, \"lung\": 0, \"cell\": 0, \"tumor\": 0, \"disease\": 0}\n",
    "    for r in results:\n",
    "        already.append(r[\"data\"])\n",
    "        if r[\"category\"] == \"mri\":\n",
    "            case_counter[\"tumor\"] += 1\n",
    "        elif r[\"category\"] == \"word\" or r[\"category\"] == \"flare\":\n",
    "            case_counter[\"abdomen\"] += 1\n",
    "        elif r[\"category\"] == \"xray\":\n",
    "            case_counter[\"lung\"] += 1\n",
    "        elif r[\"category\"] == \"cell\":\n",
    "            case_counter[\"cell\"] += 1 \n",
    "        elif r[\"category\"] == \"x_ray_disease\":\n",
    "            case_counter[\"disease\"] += 1\n",
    "    for d in data:\n",
    "        if d[\"image_path\"] not in already:\n",
    "            data_to_process.append(d)\n",
    "    print(len(data), len(data_to_process))\n",
    "    print(case_counter)\n",
    "    Stop_cnt = 750\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=24) as executor:\n",
    "        futures = [executor.submit(process, data_to_process[i], case_counter, Stop_cnt) for i in range(len(data_to_process))]\n",
    "        # futures = [executor.submit(process, data_to_process[i], case_counter, Stop_cnt) for i in range(0,30000,1500)]\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processed\", unit=\"iter\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                with open(output_json, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "                with open('./dino_instruct_0529_1_backup.json', 'w', encoding='utf-8') as f:\n",
    "                    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your own api key.\n",
    "api_key = \"...\"\n",
    "gen_intruct(api_key)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
